{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e8e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "print(\"numpy\", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bcfd3",
   "metadata": {},
   "source": [
    "## 1) Shapes and dtypes\n",
    "\n",
    "Two frequent sources of bugs:\n",
    "\n",
    "- silently getting shape `(n,)` vs `(n,1)` vs `(1,n)`\n",
    "- silently getting integer dtype when you expected floats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419d7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "y = np.array([[1], [2], [3]])\n",
    "print(\"x.shape\", x.shape)\n",
    "print(\"y.shape\", y.shape)\n",
    "\n",
    "a = np.array([1, 2, 3], dtype=np.int32)\n",
    "b = a / 2\n",
    "print(\"a dtype\", a.dtype, \"b dtype\", b.dtype, \"b\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfbc6a7",
   "metadata": {},
   "source": [
    "## 2) Views vs copies\n",
    "\n",
    "Slicing usually returns a **view** (shares memory). Advanced indexing usually returns a **copy**.\n",
    "\n",
    "This matters for correctness and performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d0439",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.arange(12).reshape(3, 4)\n",
    "v = m[:, :2]\n",
    "v[0, 0] = -999\n",
    "print(\"m after view write:\", m)\n",
    "\n",
    "m2 = np.arange(12).reshape(3, 4)\n",
    "c = m2[[0, 2], :]  # advanced indexing copy\n",
    "c[0, 0] = -999\n",
    "print(\"m2 unchanged by c write:\", m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb4814",
   "metadata": {},
   "source": [
    "## 3) Broadcasting (the rule you must internalize)\n",
    "\n",
    "Two shapes are compatible if, from the trailing dimensions, each pair is equal or one of them is 1.\n",
    "\n",
    "Broadcasting is _conceptual_ repetition without materializing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aee3a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.default_rng(0).normal(size=(4, 3))\n",
    "mu = A.mean(axis=0)  # (3,)\n",
    "centered = A - mu  # broadcasts (4,3) - (3,)\n",
    "print(\"mu shape\", mu.shape)\n",
    "print(\"centered shape\", centered.shape)\n",
    "\n",
    "mu_col = mu.reshape(1, -1)  # (1,3) also broadcasts\n",
    "print(np.allclose(centered, A - mu_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9e4fbd",
   "metadata": {},
   "source": [
    "## 4) Vectorization patterns: distances and similarities\n",
    "\n",
    "Example: compute pairwise squared Euclidean distances between two sets of vectors.\n",
    "\n",
    "If `X` is `(n,d)` and `Y` is `(m,d)`, we want an `(n,m)` matrix `D` where:\n",
    "\n",
    "$$D_{ij} = X_i - Y_j_2^2$$\n",
    "\n",
    "We’ll do it without explicit loops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a369626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1)\n",
    "X = rng.normal(size=(5, 3))\n",
    "Y = rng.normal(size=(7, 3))\n",
    "\n",
    "# (n,1,d) - (1,m,d) -> (n,m,d), then sum over d\n",
    "D = ((X[:, None, :] - Y[None, :, :]) ** 2).sum(axis=2)\n",
    "print(D.shape)\n",
    "print(D[:2, :3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b419854",
   "metadata": {},
   "source": [
    "### Alternative via dot products\n",
    "\n",
    "Use: $x-y^2 = x^2 + y^2 - 2x^Ty$\n",
    "\n",
    "This is often faster for large problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f11437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = (X**2).sum(axis=1)[:, None]  # (n,1)\n",
    "Y2 = (Y**2).sum(axis=1)[None, :]  # (1,m)\n",
    "XY = X @ Y.T  # (n,m)\n",
    "D2 = X2 + Y2 - 2 * XY\n",
    "print(np.max(np.abs(D - D2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05bf9c9",
   "metadata": {},
   "source": [
    "## 5) `einsum`: express linear algebra cleanly\n",
    "\n",
    "`einsum` can make tensor contractions explicit and readable once you get used to the notation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33421a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch dot products: for arrays (n,d) and (n,d) -> (n,)\n",
    "u = rng.normal(size=(4, 3))\n",
    "v = rng.normal(size=(4, 3))\n",
    "dots = np.einsum(\"nd,nd->n\", u, v)\n",
    "print(dots)\n",
    "print(np.allclose(dots, np.sum(u * v, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0496488",
   "metadata": {},
   "source": [
    "## 6) Numerical stability: softmax and log-sum-exp\n",
    "\n",
    "Softmax is a classic ‘looks simple, breaks in practice’ function.\n",
    "\n",
    "Naive: `exp(x) / sum(exp(x))` overflows for large `x`.\n",
    "\n",
    "Stable: subtract max before exponentiating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb2fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_stable(z: np.ndarray, axis: int = -1) -> np.ndarray:\n",
    "    z = np.asarray(z)\n",
    "    zmax = np.max(z, axis=axis, keepdims=True)\n",
    "    exp = np.exp(z - zmax)\n",
    "    return exp / np.sum(exp, axis=axis, keepdims=True)\n",
    "\n",
    "\n",
    "z = np.array([1000.0, 1001.0, 999.0])\n",
    "print(softmax_stable(z))\n",
    "print(\"sum:\", softmax_stable(z).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e165f87",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## Exercise A — Batch cosine similarity (no loops)\n",
    "\n",
    "Given `X` shape `(n,d)` and `Y` shape `(m,d)`, compute cosine similarity matrix `(n,m)`.\n",
    "\n",
    "## Exercise B — PCA via SVD\n",
    "\n",
    "Implement PCA: center data, compute SVD, project to top-k components.\n",
    "\n",
    "## Exercise C — Verify broadcasting intuition\n",
    "\n",
    "Create 3 arrays with different shapes and predict the result shape before executing the operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter for Exercise A\n",
    "def cosine_sim_matrix(X: np.ndarray, Y: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    X = np.asarray(X, dtype=np.float64)\n",
    "    Y = np.asarray(Y, dtype=np.float64)\n",
    "    Xn = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    Yn = np.linalg.norm(Y, axis=1, keepdims=True)\n",
    "    # (n,d) @ (d,m) -> (n,m)\n",
    "    return (X @ Y.T) / ((Xn + eps) * (Yn.T + eps))\n",
    "\n",
    "\n",
    "X = rng.normal(size=(3, 4))\n",
    "Y = rng.normal(size=(5, 4))\n",
    "S = cosine_sim_matrix(X, Y)\n",
    "print(S.shape)\n",
    "print(S[:2, :3])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
